{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "This is my 3rd project in the deep RL course offered by Udacity. [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ddpg_multiagent import Agent\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Tennis_Linux/Tennis.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_itter = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_itter.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_itter.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG Agent & Model Architecture Explanation\n",
    "\n",
    "\n",
    "#### DDPG Agent\n",
    "DDPG is very similar to the DQN agent, but is well suited for continuous problem spaces. \n",
    "\n",
    "It consists of two neural networks that work together to solve a continuous learning problem. The actor network models the agent's actions (policy based approach), while the critic network uses the actor networks action to approximate the maximizer of Qvalues in the next state (value based approach).\n",
    "\n",
    "This key adjustment makes it different from other actor-critic agents, and more similar to a DQN learning approach. \n",
    "\n",
    "DDPG utilizes a replay buffer, soft-update logic (similar to DQN), and incorporates a noise adjustment to predicted actions (from the actor network) to stabilize learning. \n",
    "\n",
    "This implementation of DDPG can train multiple agents at one time. The key to this approach is appending each agents state, action, reward, next_state, done tuple to the replay buffer (and sampling from the shared experience). All the same agents are trained off the same actor-critic networks. Instead of one learning adjustment per action step, the network makes 'n' adjustments. Taking more learning steps (from the shared replay buffer) allow for faster training.\n",
    "\n",
    "### Network Architecture\n",
    "I have two networks that compose my DDPG agent.\n",
    "\n",
    "#### Actor\n",
    "- consists of four fully connected layers\n",
    "- relu activations in between each layer, and a tanh activation on the output\n",
    "- the state inputs are put though a bachnorm layer before being fed into the netowrk\n",
    "- there outputs of the first fully connected layer are put through a bachnorm layer as well\n",
    "- the first layer has 400 nodes, and all the other layers contain 300\n",
    "\n",
    "#### Critic\n",
    "- consists of four fully connected layers\n",
    "- each layer has a leaky relu activation \n",
    "- after the first fully connected layer, we concat the output with teh action predictions from the actor network\n",
    "- this gets fed through the last 3 fully connected layers\n",
    "- the first layer has 400 nodes, and all the other layers contain 300\n",
    "\n",
    "\n",
    "### Hyperparameters\n",
    "I chose to implement four learning steps as my 'n step' parameter. This allows for the agents to learn quickly, but provides enough stability keep the networks from over-adjusting/over-fitting early on in training (before they have had time to explore the full environment). \n",
    "\n",
    "The actor has a LR of 1e-4, and the critic has a LR of 3e-4. I do not decay the L2 weights on the ADAM optimizer for the actor and critic. \n",
    "\n",
    "I also include a scale factor (1/sqrt(episode #)) to the noise adjustment. This lets the model rely more on its predictions (from the actor network) as the training steps go forward. This enabled the current model architecture to solve the environment. \n",
    "\n",
    "In this experiment, I do not discount future rewards. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets train the DDPG Agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=state_size,\n",
    "              action_size=action_size, random_seed=777,discount_rew=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 25\tAverage Score: 0.00\tMin Score: 0.00\tMax Score: 0.00\tEpisode score: -0.00\n",
      "Episode 50\tAverage Score: 0.00\tMin Score: 0.00\tMax Score: 0.00\tEpisode score: -0.00\n",
      "Episode 75\tAverage Score: 0.00\tMin Score: 0.00\tMax Score: 0.00\tEpisode score: -0.00\n",
      "Episode 100\tAverage Score: 0.00\tMin Score: 0.00\tMax Score: 0.09\tEpisode score: -0.00\n",
      "Episode 125\tAverage Score: 0.00\tMin Score: 0.00\tMax Score: 0.09\tEpisode score: -0.00\n",
      "Episode 150\tAverage Score: 0.00\tMin Score: 0.00\tMax Score: 0.09\tEpisode score: -0.00\n",
      "Episode 175\tAverage Score: 0.00\tMin Score: 0.00\tMax Score: 0.09\tEpisode score: -0.00\n",
      "Episode 200\tAverage Score: 0.00\tMin Score: 0.00\tMax Score: 0.10\tEpisode score: 0.050\n",
      "Episode 225\tAverage Score: 0.02\tMin Score: 0.00\tMax Score: 0.10\tEpisode score: 0.050\n",
      "Episode 250\tAverage Score: 0.04\tMin Score: 0.00\tMax Score: 0.19\tEpisode score: 0.150\n",
      "Episode 275\tAverage Score: 0.07\tMin Score: 0.00\tMax Score: 0.40\tEpisode score: 0.05\n",
      "Episode 300\tAverage Score: 0.09\tMin Score: 0.00\tMax Score: 0.40\tEpisode score: 0.05\n",
      "Episode 325\tAverage Score: 0.14\tMin Score: 0.00\tMax Score: 2.60\tEpisode score: 2.60\n",
      "Episode 350\tAverage Score: 0.31\tMin Score: 0.00\tMax Score: 2.60\tEpisode score: 0.050\n",
      "Episode 375\tAverage Score: 0.40\tMin Score: 0.00\tMax Score: 2.60\tEpisode score: 0.150\n",
      "Episode 400\tAverage Score: 0.54\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 0.15\n",
      "Episode 425\tAverage Score: 0.54\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 0.15\n",
      "Episode 450\tAverage Score: 0.66\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 0.60\n",
      "Episode 475\tAverage Score: 0.73\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 2.050\n",
      "Episode 500\tAverage Score: 0.76\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 2.45\n",
      "Episode 525\tAverage Score: 0.94\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 0.75\n",
      "Episode 550\tAverage Score: 1.10\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 2.50\n",
      "Episode 575\tAverage Score: 1.37\tMin Score: 0.09\tMax Score: 2.70\tEpisode score: 1.70\n",
      "Episode 600\tAverage Score: 1.65\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 2.650\n",
      "Episode 625\tAverage Score: 1.96\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 2.65\n",
      "Episode 650\tAverage Score: 2.06\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 2.65\n",
      "Episode 675\tAverage Score: 2.19\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 2.60\n",
      "Episode 700\tAverage Score: 2.14\tMin Score: 0.10\tMax Score: 2.70\tEpisode score: 2.65\n",
      "Episode 725\tAverage Score: 2.09\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 0.050\n",
      "Episode 750\tAverage Score: 2.08\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 2.65\n",
      "Episode 775\tAverage Score: 2.04\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 0.15\n",
      "Episode 800\tAverage Score: 2.12\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 2.60\n",
      "Episode 825\tAverage Score: 2.14\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 2.650\n",
      "Episode 850\tAverage Score: 2.24\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 2.65\n",
      "Episode 875\tAverage Score: 2.31\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 2.60\n",
      "Episode 900\tAverage Score: 2.42\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 2.600\n",
      "Episode 925\tAverage Score: 2.41\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 2.550\n",
      "Episode 950\tAverage Score: 2.28\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 2.650\n",
      "Episode 975\tAverage Score: 2.18\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 2.60\n",
      "Episode 1000\tAverage Score: 2.01\tMin Score: 0.00\tMax Score: 2.70\tEpisode score: 0.05\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJztnXmcXFWVx3+n906609k6W2fphGwkJAHSQBCEyL6rAwqMiuCSUdl0cBxwAcfPLG6jo6ICKiqKgAoyDEQiQmRTkCRkIyQkhEA6+9Lp9N5d3Xf+qFfVVdVvuffVvW+pOl8+Tareu++++96rd86955x7LgkhwDAMwzAAUBJ2AxiGYZjowEqBYRiGScNKgWEYhknDSoFhGIZJw0qBYRiGScNKgWEYhknDSoFhGIZJw0qBYRiGScNKgWEYhklTFnYDVBk7dqxobGwMuxkMwzCxYvXq1QeFEPVe5WKnFBobG7Fq1aqwm8EwDBMriOhtmXJsPmIYhmHSsFJgGIZh0rBSYBiGYdKwUmAYhmHSsFJgGIZh0rBSYBiGYdKwUmAYhmHSxG6eAsOsfrsFv3n5HXzyjOmYO2GErzo27mpFb/8ATpw6CgCwbucREAELJ4/U2VRHnty4F80tnVgyYwyaW7rQ1ZfAwAAwvLIM8yeNwJTRwwAAW/a24Wh3H05qHI3uvn7837rduGLxZCQGBP6wZhfOOnYcfvD0VjS3dKG2qgx9/QLjRlTiXy+Yi8qyEjyyZhfauvtw0cKJuOfZ7ZhRX4P3n9CA+19+GzsPd2LXkS7UVJaht38Aly1qwLNv7Meh9l6UlhAuOG4C5kyoxY6DnfjbmwdRWV6KL5w/B2Wlyb5kR08C31qxxbqGTjS3dOEz7zkG2/a1Y0JdFWbU16B/QODh1c04d954fO/prZhYV4WWzj5ccNwEPPrqLiyeNgpv7GvDR5ZMw6s7j+CMWfX45orNeN/xDVg0ZSTauvvw0Cs70dzShQ8vmYbuvn4kBgRGVpejuaULcyfW4s5ntmHJjDGoqy5HRRmhhAgrtxzApt1HUULAhQsmYH1zK/Yd7UZFaQnaexKorigDWdcwaWQ1bjxrJjbsasWja3ejN9EPAqG6ohRt3QlUlpfg3TPH4s0D7ehNDGDqmOE4ZfpovLT9ENY1t6K8lPCZpTOxasdh9PYPYMqoYbj/5XcweVSy3qdf34+5E2uRGBDYtr8d8yaOwD3Pbcepx4zB1SdPRWtnH57begCXLppk+1vpHxD4+Ytv4czZ9Zg1vtb4b5PitkZzU1OT4MlrxU3jrU8AAOZPGoEnbnp3XnXs+PrFtt9NcrS7Dwu/+ifH/cMrSvHa1y4Y0q7/eGITfvL8W/jpNU3YvPcovv2nNxzrWHbGDJw/fwIu//FfAQD1tZU40NYDAHjf8ZPw6Nrdvtr+tffOxzWnNgIAbvntOjy8pjlr/9wJtdi8ty3d5t++shNfeHi9dP2Xnzg5XeeOr1+M63+zBk+s3+NYfuHkOqxvblW8iqHMGleDrfvb865HlXV3nIfPPvgqVm45gL98fikaxw4fUmbjrlZc8oMXcPyUkXj0+tN8n4uIVgshmrzKsfmIiS17WrvDboIvOnoS7vt7+2237zuaFOptPX3YdcT92vcf7c46T0ohAEgLbT909Ay2bfeRriH7dxzqyPp+uLNXqf7tB7MF866WoefI5K2DHa77Zcltd1D0JPqx07rGnsSAbZl26znuaXW/F7pgpcDElury0rCb4IsuB6GvQk9CrY6q8sFXvUVRUGcyrMLsPVe+N/EydAyhu3dQEfQP2F9MV1/ynlSWBfN7Z6XAxJZqwwLKFKmXPB96+ux7lZk4ycuWjj7f5/VSxE69XVm6Fe9Nt6JydKKvPxzt0tk3OJpz+l2kFGVFWTDimpUCE1viOlLo9hDodteV2YsUQm6kkClgM12Hvf3+BXeVhyLOdVGquiydTGdOhCXMddGZcb1OCjFVpqKUlQLDDGEgQzjGVSn0ePSG7UZA3X39IEp9HpDqkeswU+Vi+p53G2hzlMm83k6Ha0+NIIIaKXBIKhM4vYkBtHX3oTsxgFIijB5eIfWD700MoLVr0PTh1Wt1oj3DAdvd14/SEkp/70n0oycxgOEVZVnbD7b3oLKsBLVV5Vl1DQwItPUkUF1eit7+AfT3C9RWlaEk41gAEELgaFcCZaWUdQ12HO7oxZHOXowcVpHe1tGbQEtn8rgDbT3YtPuoax3723qynLD5mnVSHGpPOqyPdPZiX5u7s3vL3ja8dVAtoqct49nsPNyJQx09LqXjz1uHOvC25eTeur8NcyfUoqSE0NXbj5rKMggIbN2XDAwIaqTAIalM4Fzyg+excdegUJs3cQSW3+wdWvq+H76ItTuPpL+fP3887v6IZ4TdEFJhngAwtqYCKz+/FAusENEpo6ux83AXrmyagm9csRAA8PahDpz5rb8AGBqy+l9/fB13P7sdc8bXYov18t501kz883lzACSVwZMb92L7wQ58a8UWpXau/vI5WPzvfwYAnDdvPP60aZ/ytZrgrg8vxqd+vTrsZhQdp88ci19/4hTfx8uGpPJIgQmcTIUAAJv2uPd6U2QqBEBPNMbB9l5kBn3sPJwM+3vk1ea0UthxqNPx+FQMfUohAMDyjXvTSmH5hr24/jdrfLctxZp3WlzL/vzak9DZmxz1OAnsd88ai+e3Hszadu+1TejqHcCvXtqBl7YfRl11Of77A4uwrvkIfvDMNtt6Xtp+SPFKBvnB1SfgxgdeVT7u6pOn4IG/75QuP2d8LW45bzbWvHMEdz37JgDg7o8sRqJfoLqiJO2oryovxXW/eCV93M+vOwkJy0/RmxhAdUUJvvf0Nqyzfnu3XTgX//XHzenyJ0wdifbuxJA5Dh89dRpWvd2C1xxGdIsm12GdhvkVJmClwDA2g+V8BtCZo++D7XrMH27tmVhXhffMHedZx+Jpo7KUQnV5Kc6aOx4A8PbhDry0/TBOmzkG58wbj3EjKh2VQj5cumiSo1K4eMFEPLHBfqLapYsmKSmFk6aPwnnzJ6C+tjKtFM6fP8G27NiayvRzOnNW/RDT3+a9bVi38wiqy0txyaJJWUrhjFn1aLNRCkvnjsP4uipHpXDG7Hoc6uhFs8c8jEwSA3pMgF6wo5mJLSYNn/nUHVWDLIGk97mVNWZydj6la3vsKLW88mUl3iKOyP6zDET2x3hVQ1APvw1IJ5hTCkQ0hYhWEtHrRPQaEd1sU2YpEbUS0Vrr73ZT7WEYJ4SNGNcl+PKpJ7NdJsSwqgA0jc7mpHr7EjrBk0yFlNtGFUWbi1O0kRNBjRRMmo8SAG4RQqwholoAq4noKSHEppxyzwshLjHYDqZA0Se4bbblVaGeeqIaA2KqWSUatVSJwkhBFqfm+W216iTGoKZkGBspCCH2CCHWWJ/bALwOoMHU+RhGJ3n5FDTVM5BxsA4F6CZzc/eFMYpQaZ8XqXBimSjOzKrJ5kRu5iVHRUHk3mYi5d9GfyH5FIioEcAJAF622X0qEa0joj8S0fwg2sMUBro6Tro7YLpGMNff7y9qyTSmRjAmRgqlOkcKkttMkcdEdCWMRx8RUQ2AhwF8VgiR64pfA2CaEKKdiC4C8CiAWTZ1LAOwDACmTp1quMUMo4985GdmKKwOOTzUHu68LwxcO9aKdaUCiEolFI2KLrLzEzg5mnVeD1AgIwUiKkdSIdwvhHgkd78Q4qgQot36vBxAORGNtSl3jxCiSQjRVF9fb7LJTBEShwmcUWqinWNeCxo1U9p8VJp/pR5WoMBwyqKqG5PRRwTgZwBeF0J8x6HMBKsciOhkqz3+Z8YwxUWEBGUm2T6F6DRSl0/BXESqSySPovQddDTrk9pObVBtW/IY9fMHpRRMmo9OA/ARABuIaK217YsApgKAEOIuAFcA+DQRJQB0AbhKROktYooC/T4FzRUiWsrFFDp73SmlIOOn8AoddXc0OykK/aOIRNyVghDiBXgMCIUQdwK401QbmMLGmBkjT6LaLjdUJoeZC0nVV1cq6khmpCArvJ2KBWVBGoi7+Yhh4kIcOuFaHM0KXVfVGcQ6cDcfqdU1OHlN73XI1kbWf277VYn9SIFhdHGwvQfPvXHAWP26e/aZSibKCsePLRww6FMwYD7S4VPwVFYB6c+BgH5MrBSYyPNPv1qN1W8PzRIaVYFrpF2Gr1Vt8pqZxrg6whXrSoWilsqYj2QrtQ09dfYpuFYVYUczm4+YyLPvqPtiLnlj8F0Lwr8QVeWoit+Rix0lJfJKQRZK/y93uz/FEFVYKTCxpVCEoQx6fAoaKoHJkFSXfao+BaXJa/LRRyr7dBPUz52VAlP0qLxsMqGhIitnkY8GKeJXMEVlUpaJc5YacDQT2TuP/abOjiqsFBhGM8Lhc151GtYuKqabMCavqaIzj5IbQQr3oEbGrBSY2KLLXq/yssmUjWr0kYrQdV1kJwRHs6r4DUwp+Jy8EGV/AysFpqjoSQzNYW/SGaxNcWmpxZkoyCidglwmZXYK6clrDrOUHfWCZskf1Kx2VgpMbPHzjnzyPvtF7XUS1RnNStlAQ8h95Ia6ozn7gAUNdXmcW30SmnfqjCioYXt4ngJTVNhNglMyH8mUMWA+MiKIIyaXTExeA4C/3noW6qrL867Tbp6aW44j3bc3KF3MSoGJLdHsj5vB9OhDRSDHYTnOzPkJk0ZWu5b1nGimo0Exgs1HTNGjPSTVf1OMoiLcwhCEriGyinXpznkEpJbYtAlJdQhT1W4h4ugjhoknZlJn668zExX5FaWIKidUdEIYyf+iDCsFJrbos9fLVyRXMnPyWnQkqDZHcxi5jxS73TIzmWXxapevyWsR1kOsFBgmBhgPSY2AlDKR+0juvJLlYONo9iivE3Y0M4wn0Z281tc/gP4BESlTS66ZxCNo0nlXGLmPFOvS6bQ2oS6jbLLikQLDaEYAuPQHL2DuV57UW6lBIjBQ0Cp91XwKkuVsnMeO4agOTul84MlrDBNThBDYvLct+dngeUZUhTPQj9DgJ3SioEt1w0qBiS1hTAwLa7ay3XlVe6L6ZjQbcjRrXI5TZyfdT4/fxCI7nDqbYWJKVpbUmHSro9DjDcuEJS/0h6bOdk2BEYWb6gNWCkxs0ZaWWqEm5SypBp3hJoWOW9Vh6DlVx6xOR66f+2xiPQVOnc0wMSXoRXb8ktXLjWu3VgMqjubcwjrXlY4KrBSYokdFcG/d126uIS7YNVFV6KjYxt3KxiFLalAS2e9p/PkUOPqIYVwJY7bwpXe+4FnGxMprplFKc2GsFfpQkrkGEuLFeeDFSoEperQLOSO5j+Igigsbgo2wd8+BofX87FNgGA9isf6xprptzUeqIalDjpcvm9WWGCgoJVOZd2U+jvWaLx7doQQrBYbRTPRF5lDibO4ICqLopx/XgTGlQERTiGglEb1ORK8R0c02ZYiIvk9E24hoPRGdaKo9DOOESSGubzQzdJu6o1lP2VBCUlUnr5lphvz5Yzx5zeQ8+QSAW4QQa4ioFsBqInpKCLEpo8yFAGZZf6cA+LH1L8N4ElUrRhzMK7lE2ZxhGi9TU7HdGWMjBSHEHiHEGutzG4DXATTkFHsvgPtEkpcAjCSiiabaxDB26JbhQc1oNtl7dlUSYYSkqk5eMyDJCWpJ7njlNReIqBHACQBeztnVAGBnxvdmDFUcIKJlRLSKiFYdODB04XWmOIlqf9zEjGYTZMostTWao3tNfjCxIE6cRxfGlQIR1QB4GMBnhRBHc3fbHDLkFyeEuEcI0SSEaKqvrzfRTKaoKSwhx5gxh6k7mjWHpBbC5DUiKkdSIdwvhHjEpkgzgCkZ3ycD2G2yTUzhoMt2r998FFSaC1WTinwApXuWVKXTasFkllSVldfk6/TwU0Q43Mtk9BEB+BmA14UQ33Eo9hiAa6wopCUAWoUQe0y1iWGCINt8VBhEWIYZJ7PHb0LZyBKUMjYZfXQagI8A2EBEa61tXwQwFQCEEHcBWA7gIgDbAHQCuM5gexjGFt3vWmQdzZqEVCxGCkplg9d4UdaxxpSCEOIFeFy7SI7/rzfVBoZh5PCMq8egsis0R7MXUXE08yI7DBMQ2nu+AUUf5Zs4NE4LxCj35k2EpNLQRXb8NiFq9zcTVgpMbInqHLG49KTrayrTn72EXaYCiep994uROQ0G6gxqUiQrBabo0S3Es95dl6rPOXac1vOq8suPnRzq+U2ideW1zM8hOpqDgpUCw4TEkhlj8jpefeGZ7AMm1FVl7MstmrMWccbnOOQ+ChvPkVdA7fADKwUmtphc/ziv+hw+FwpxMB8FZRIKUlmxo5lhAkK7UpCsMN8JTOqL2cvvU5nMFgQmV+P0nmjmvM/tUbs9n6KcvMYwpolDjzWOGVO9KcRr8iZsfwKvvMYwAaHd0SxZLl+5EWTqh7BTa6tfq76V1/zOaHarOMIDBVYKDOPGkc5e/GjlNqVjstJcxKRTrSJE43JNuglbMQYFKwUmtugSTm71fOnRjXj5rcN6TpRDlHuLQ4hTWxHcvQ3qPEtmjA7mRGClwDCutHcn8jreTW/lbT5SLq+QJdWlbDgDhRC1EmV+zG6Hu6PZ3z47Tpk+xjqf+bvPSoGJLUHMHM73DIViasmapxCDizKhQsJ0NAc5qmSlwBQ9bjIuXwHoprjyDklVPN6t+BDHcsTMRWFlhAXcZzS731P9nuYg9DErBYYJiagJXjcy2xr9cYIZwkzHHaSTm5UCE1u0OZoNirkoWVpUsnZGTV+ptydqV5CN39YF8XNipcAwIRFtsZVNZk81SoouCDLNQLLPTHU9Z5n6goKVAhNbdMmm0IRcnOxHGcRBJ5jJfRTP56UKKwWGiSk6na9DbNYRczyHKZCzHc0KM6UNzGjmkFSGcUObT8EccQjfVCUO12QkJFWlrO6QVL3VucJKgWEMYlJ8ag279Mh1FLbhJOzzp9ClGPxGE7GjmWECIA49X0YNneYmP1VpD0llRzPDeKMrlHTARSnkqy9M6huTsetDJ2mFG32k7D8x0giNVfn2KehrgxOsFJiiZ4AHCowLmQJcVpgnQ1J1jlZ48hrDeBJEltS8645FAKfE6mMZn+NwTUZCUvVXqUwQ956VAlP0uJmPoozJzmMUBGAmUVnLQFtIqoa2mIKVAlP0uCbEy7NnFlN9M5TM3EcxuCatppsIJdlgnwLDuKBvRrNBR3N+h7uiNY1C7vewZ6vlEIXmhBnRVBDRR0R0LxHtJ6KNDvuXElErEa21/m431RaGcSO0yWuaun2y1eRzuuz1FPzX44bOek3O4Qj6/EFTZrDuXwC4E8B9LmWeF0JcYrANTAGja36BSZ9CHEwtgJoQi4Oj2QRhyvmCSJ0thHgOgJnFbRlGI24hqUbnKWhaZEclTFK6bodzmSTqvWt1k4/b8qcFsMgOEZ1ORNdZn+uJaLqG859KROuI6I9ENF9DfQyjjMmRQlwim7yEFMXN0Ry6ginwGc1EdAeAfwVwm7WpHMCv8zz3GgDThBCLAPwAwKMu519GRKuIaNWBAwfyPC1TKAThaM67bpd9Fy+YiGEVpb7r1iknUiah1K0IX6hmE7X2pPBt1ono9QDyI4X3A7gMQAcACCF2A6jN58RCiKNCiHbr83IA5UQ01qHsPUKIJiFEU319fT6nZZghmOz5uo0URg+vwB9vfre5k2ske/Ja9AlqNrGTf0X3Ijte59OJrFLoFcnulAAAIhqe74mJaAJZd5uITrbacijfepnigEifMHf1KeT7EsYkJjUlRFPyz1WohpL7KPyutd65D2bL54Ns9NFviehuACOJ6JMAPgbgJ24HENEDAJYCGEtEzQDuQNLsBCHEXQCuAPBpIkoA6AJwleB0lYwkWk0nIZmPgOjM1PUiCkJZBTMrrymUNdSGICSklFIQQnybiM4FcBTAHAC3CyGe8jjmao/9dyIZssowvtD1fphMiFeI/ZxiC0mNgjoMUid7KgUiKgWwQghxDgBXRcAwQaG352oy+sh9fz6XYVROuK/OGTjK5paAGuw20nPd57OBkVhkRwjRD6CTiOoCaA9T5KxvPiLVu9b5zvcPOO9zaso7hzrR0tHrWfee1i6frYoucRj8BGWWc3Y0aw5JDVAty/oUugFsIKKnYEUgAYAQ4iYjrWKKkqc27cMn71uFb1y+AFeeNNW1LBG0SSfVuQRCCJzxrZWorSxD3bBy17Kv7GjJp2mu+BE8x04cgdf3HJWo2/l7GDohTJdGlNJwB2GOlI0+egLAVwA8B2B1xh/DaOOtg+0AgK372j3L6uw5qb5mqfeyrSehrQ1B8ZNrFofdhEAw42geWqnT7zCf058wdaTNufOoUBFZR/MviagCwGxr0xYhRJ+5ZjHFiNLEKQpv8prOvlrQPoWyErl+oJ34SxGG8zzMKC0T53Z77tXlzhMag7jzUkqBiJYC+CWAHUj+OqYQ0Uet/EYMo4XUD17GLKI3JNVln235GBjVHYhZZKlvTFymSp1xvs+yPoX/BnCeEGILABDRbAAPACiOsSgTCOmRQsDndfUp2OzSGcIal/j/sH0KUSXo8NwoJcQrTykEABBCvAFrIhrD6CL9gknISZ0zmlXriUqcvq88/9J1B2sy0X1s2Osp5FOn3b4gOw+yI4VVRPQzAL+yvn8I7GhmDCFjw9Vp51WPPtJ26tDj/2UJYpGdqGMrrB0dzXF5skORVQqfBnA9gJuQ/H08B+BHphrFFCcqwoZIX49deaSQUb65Jbx5CCYFj1vNoYSkBnCE+Zoy6/RZa1TSXFjlvieE+A6QnuVcaaxVTFFTImM+0ng+t5GCneLRaT4K3KXgN9OzhnY6VfHza0/CqOEVWPHa3vxPkjpX2LmP8jj/sRNG4MVt2blBg/yZyPoUngZQnfG9GsCf9TeHKWZSUT1BC0pVx3FUzCcm75Nr3ZpvwJwJtTh+ytDY/OwGaT1l6Djd34eWLcGSGWMcj4tS6uyq1NoHAGB9HmamSUyxomY+In2OZsUXTedqakHbnv2eT0c7g3SW6jxTkJ2U8SOqQm+DrFLoIKITU1+IqAnJdNcMox05R7M+lEcKGs8dR4r1+qPgPI5M6mwAnwXwOyLajeRvYhKAK421iilKlH7vGkNS3Sqy26U1+ihgOSN7vlwBqGONZqdTy7RJVSDrHZUEOMJxOFVkfApEdBIRTRBCvAJgLoCHACQAPAngrQDaxxQRKmkuQh0pRMWpwARKUI5mN6KQOvtuAKn8wKcC+CKAHwJoAXCPwXYxBcY9z72JjbtaXcukbPtSqY80vnUvv6W2CmxU5in4uQfyk9ecj9vg8Rxl6xysW8JcqDp5Ta144Dg9O8d5DxGavFYqhDhsfb4SwD1CiIcBPExEa802jSkk/nP5ZgDAjq9f7FgmLWwlXwBdsnn5BrVQSB4nRJ+wZzSbEuJRSJ1dSkQpxXE2gGcy9sn6IxhGirROkCgbVMfJ7hXUGX2UT5c2yN6wyZ5q0OZCvwThpXAcTUUodfYDAJ4looNIRhs9DwBENBOAvzEkw3ggKyTCsu3H2aUQZgK+IKN3dJ4rCgopReips4UQ/0FETwOYCOBPYvAtLAFwo+nGMUWGgrQNU7hpndEcKZHDuKLwm9P9VIP8lXiagIQQL9lse8NMc5hiJt3jCHg9BTfsRiNRGSmYzZKqXrdfTAQWRGkJTdu6ItwXkJ28xjDGUVlPIUyfQpznKfglLu00ga8oL1MhqRFaT4FhjKNmlikM81E++IuKkSwX5P2NiaNZJ86hp04HBHcHWCkwxpF1CCtNXtM5o1kRnSuvxYWiHin4OsZQSGqEEuIxjG9UhXfQazSrojPqKa/Ja75WGZA7JlifgoHJayGnzvZbl/OktuBgpcAYR1aEqoraIHpNpnMfxYW4RUkZWU5Ue40+YJ8CUwiYMh+FhV5HcyREDeOC6nrKXsfoboNujCkFIrqXiPYT0UaH/URE3yeibUS0PjM1N1NYyI8UFOYpsKPZn6CQdjRrOJckRrKk+myLKtozxnqdz9/plDA5UvgFgAtc9l8IYJb1twzAjw22hQkR6RcnHZIqZ2MOy4wTkSwXTECYnA8iX18BRB8JIZ4DcNilyHsB3CeSvARgJBFNNNUeJjxketaZJqao58LRmvsoD3wNFGRHCjkFTd5vqboj4WjWmDrDp9mp0OcpNADYmfG92drGFBgyP2Qh1IbGRBTIUNp28prG+tmlEB/CfFQF4VOQwO4ybd83IlpGRKuIaNWBAwcMN4sJA4HB0UJJxAVlRAYKviSFdJoL5Zr9IxWCrLyegs6EeM51OU82865V9VxA4c9TaAYwJeP7ZAC77QoKIe4RQjQJIZrq6+sDaRyjD7mRgshIcxFtraB3nkK0r5VxJ6gOQrHMU3gMwDVWFNISAK1CiD0htocxhIwNXkDVfBRi6uxQzqqHYgmBDXuJZmMzmgP48RlbKIeIHgCwFMBYImoGcAeAcgAQQtwFYDmAiwBsA9AJ4DpTbWHCReZ3LERE5ymYzpIa0UV2Ipcl1UCdqtjdE7/3SdXRHKVFdnwjhLjaY78AcL2p8zPRwUSPnhCeozkq0UdMsKj0/uM8IOMZzYxxpEYK1n+AGcejTqKSOtvsegrB3WC5kaGyp1kbRkYdPs8V98lrDANAISTVZj2FlZv3o7mly8c5Bb755GZs3ntU+VjPumPtVWB8E2JHpCAmrzFMmjxk6HW/eMV2O3nU29aTwI/+8iauvHvIwoFKmEqIt2hyHYB8s6T6OCaCZg2pGewG6tTBZYsmOZzfHceRj+fktcIOSWWKBLkZzYM/eJ3mhAEDix/I+hSmjRnmuO+Gs2bpag5jGKff2rXvasTwSmNu2ZxGBHMagJUCEwBS5qMMxSEbjRKWEadfUtG4rTWd2hN0iGixzIsIe41mU8+10NNcMEWCdEiqSqUhyjbZwYfbzGwdMqNg5hwYCEEOeZqC7zodl+k00AYnWCkwxlFdT6FEIs8FKdSbD3amL9nzuo4UrF1Bi/VC0SNhoHLv4nybWSkwxpELSR0UwFLmoxClm/xIwc18lH/74yx4MjGynkLEtZ/65DWOPmIKCNXcR/mfT+AvW8wlTpR1NLu+xyRRhokEUXpGsU5zwTAppKKPMDjtkPloAAAboUlEQVSikPnduzmaf7+6Gf/y+/VyjfOBrFKQcTTnQ5SEVT7IjQz116mKzhnNqhGp7FNgCgvJyWt2n51we+n2tHZ7VyCJXVsGBuSOLXXxjaTMAcUSDRRnovSMCj11NlMkSP2MhdrQmECO5XW+wnb+A/mRgvO+sMRMoYwuvDCz8ppCWc1PuFgW2WGKBPkEcslyMtE9bi+JTPRSPsj7FJzbkTIt5ZX7KEI92HyIulPYBI6hpxG4F6wUGOPITl5LlYtSZiE7BaVlpBDSu18oisSLQr1OnrzGFASq6ynI+RTI0b7q5uDVgaxPwbSjuVDknglHs4l7o9QGz+RHaoex+YgpKGTMQcLhsxOu0Z6GXyDpkUIEnQoRsE7EjihlxeXU2UxBID1PQfEn71SvnSzu6Emg8dYnlOp3OoeWNBfI36fAOKPzvvpZO1z3c+XU2UzRITAobPN1NNu9QEe7+3y2y0yaC7dwVVkKRZ+YmNFsAp2C3q+ZiFNnMwWB7CI7KrgqBZt95aX6fuo60lyklELQwi580RoMYV+n7vOzT4EpKGTNQkqOZrd5CjZvkN8Olt1x/RrSXGgZKYQt+TQhtchOgVxrCqfQU697wT4FpiCQDklNzVOQ+Om7zlPI2DeYOsPf62R3lA7zUZnhuRRORCEOPgh0Xmd03MzBwEqBMY7sjOb0xzzfQjtx4H+k4H+egttogCevDSLnU1Cs01dL7PFjx/dSSo57PX0Kyk1RhpUCYxzpkFRNP/jMUNDUJ/lZ1d70S89TcN5XVhrSSCGUsxYGYY6yOHU2U1DITl5LCW7ppBgOgj7z9UmV8LtUs91hOtJcDDqaGRNoDUn1c359p8+Bo4+YAkB1jWY5R7PLPhuJMCChFe69tsmuYUM3aUhzUapBajlVUVXu/Frnc9qPnz7d/8F5YvdM3zOnHh9eMjWE1uSP8iI75poyBFYKTABImI+EmlPYrUTmi6XyMi2eNlrqPFpDUg2YBZ65Zan2OgHghvfMNFKvXyaPGoZ/f98C231h+1vi7M9npcAYR9WcL1veqVimMB40H3lXKhsQpCPNhcmQ1Ekjq/OuO0hMOJq1kp7RrA/HLKleTWFHM1MIyPSsBfT94O1eLJk25Arq5BKhdtFHcu2QCUkNWtjlMzKJU+837PUU4nxuo0qBiC4goi1EtI2IbrXZfy0RHSCitdbfJ0y2hwkHKXOQEMoRQs65j/xFH9kJcVvzkaRWcBsMmF7zIU5EffKanzkuXtfk7FMIf/KasTWaiagUwA8BnAugGcArRPSYEGJTTtGHhBA3mGoHEz6qaS7yzu9iN3nNxxKfmem8M9GxRnN6pBAj3RC2nb6YKZSEeCcD2CaE2C6E6AXwIID3GjwfE1FUfQQ6J6+19yTQ1dsvpWhyhbjTEbLmozBXhyt2wla2ps4fd59CA4CdGd+brW25XE5E64no90Q0xa4iIlpGRKuIaNWBAwdMtJUxiJz5CGkpLL94p33J3K1ffnSjlCC3Nx/Z+BSkzUcyI4WhZRZOrpOqP3AMCTopR3OIUn4wdbY+HLOkOm0vEJ+CbbaBnO//B6BRCLEQwJ8B/NKuIiHEPUKIJiFEU319veZmMqaRHynId4Pc6swdFew41OEr+kgIYbvKmnSaC4k1mu147IbT8dVL50mdIyjilv/HhLklCnmjgljwx6RSaAaQ2fOfDGB3ZgEhxCEhRI/19ScAFhtsDxNhstZolrT/O5Wz68jLCHLZl146+sjl7fJKiBcFAZSLqSZF70qzMWKyKdLJa68AmEVE04moAsBVAB7LLEBEEzO+XgbgdYPtYUJC1tGcVgp59obszufVBjsZ7exT0JfmIi7Eq7WGQlL1V6lMED4FY9FHQogEEd0AYAWAUgD3CiFeI6KvAVglhHgMwE1EdBmABIDDAK411R4mPFRnKOf7w7cT2l512gnppKKyqyv/kFTPLJpRkEABEcVRUb54XZLz5DWH7QHeImNKAQCEEMsBLM/ZdnvG59sA3GayDUz4qK7RLO9olt/u1bt3Ekym0lzEkThdjdbU2Rrrype4Rx8xBUSif8D3/AGpLKnIELZ5/vL9rIFgbz6yP6ZfQ/QREz9UHqd+R3dhzFNgCoR9R7sx80t/xP0vv+PreKn1FBwminkdI7N9Q3Orp2JyEuD2/gn9SuG4hhFZ36OoTkyZeUzUqnXlNQPdc9UsqUHCSoHx5O1DnQCA/127y9fx0uYgxfUUnMgdFfT2D3jOLbCNnxb2vgZ589Hg529cPpjN84mbTs8q9/iNp+P+TyyRq1SScbWVWuuLG2bMR+FL7LiHpDIMANkRwGDuI9W0GDL7Ej5X2bFTCv2Ky3HOHl+DpXPGpbfPn5Q9Oe24hjrUVZf7ap8T8yeN8C6kiJ1IHFtTkX+94cta7Xg7mvXWpxNWCkwASJqP0qXzczXb+Q8S/e51Ou218zWohqRyzqDgKURFA7CjmYkYfn+QsqmzU+X8JK/zos9uarJXm4SDslA0H/kSUIUq1WyIS0iqmqPZqy610NNCmbzGMABUJq+paR3nGc1Dd/Ql1JWCU12y0UeZpqd4iD13YiK7Aeh2NGurKhawUmA8yff9koo+ykxzkd/pbF/iPi/zkV2UUUabMpHPkprHgja+j2T0k3zgKs9E9+gnyNEUKwXGOLJCXsXR7FavndBOeJiP7PwYT23ah+aWLpv61WY0E1FBSPli9404yWU/81GczUQei+ywT4EpBGTNR2mlkG/uI5vje32Yj25+cK3tdtUV4mKW5sg3ly6ahE+deUze9Xxg8eS8jv/8ebPzboMKy86YYfwc7FNgIoXs+gFOyK6nkJa1IYSkqsh5VaWQHCjEXzN4dYgbRlbj1gvn5n2exrHDXfefNnOM6/4bzpqVdxtUGF45NFuQp6PZabvHgTxPgYkEsnH5jkhFH9nb712PcTjAbnui38t8JI+0TyEPRRAnp26hEwVHM89TYCKFj2jOLKRyH2WZj/LDTmj3ejialepXHDkRqCiEfKFeY+ppqyh5z8lrPkNP2afARAIvJ60X6ms0yx3gmCXVznzkMVJQwY/5SJVCMDcVGmEqPR4pMJEi3x68rE9BJfrI7SWxndHs1btXuDjV3hqLd0YXQViyjK6nwMSbVTsOY0xNJfx2stu6+/Djv7yJ57Ye8Cy772h3Wtg+8Pd3ML1+OCaNrHYsnyr7v2t34XBHLyaPGoY39rWhpaMXP33hrSHlvaKPVBx4v1vdLF0WAECF0e/3GiFFwfYeFbznFTjNaFZbfMcErBQYW17b3Yor7vobAGDKaGfh7Mbnf7cOK17bJ1X2E/etwqLJyURxHb39+NIfNrqWn1E/HBt2tTqGjebS56HZvCa3ufG5c2bju39+AwBwTP1wvHmgA0D2aGZ4ZRlqq8pwwfwJjvWMq63EydNHAwDedYx7hE2+/NOZamGU/3TmMagozTYsXNk0BfMmjcAdj72Wtf3adzXiF3/d4VjXhcdNwLqdR7C7tduxzM1nz8L3nt6q1MYlM0bjaFdC6ZhMRg+3T+5XbMqOlQJjy4d++nL6887DQydwybDjYGfWd691iWX9t//x/uOwdV+77b6bzp6F79sIEy/z0ftPaHDc94HFk/H1yxeiNzGAY29/EgAwfkQl/nrr2SgtIXT0JNJK4elbluKqe/6Gl7YfTguTEgKqykux9vbzXOcs/P1L56Q/N44djh1fvzj5+dYnssp984qF+MLv17teT4oLj5uA2qoy/HbV4OgmVW8m58wbhysWT8a/nD9nyL7M8nbHtvck8K0VW9JK8KuXzc9SCqfNHIMXtx1Kf//xhxfbXlcmnzt3Nm4+exZmfHG5Y5lcHlx2qnRZO+772Mm221OjSJ12fSLgoWVL8IdXd6GvX+DhNcnn4+1o5pBUJiRk8/u4kWuSqS4vde2xq5hweh3q+edz7ScueZmPqsqdXwWBpELLFAo1lWVpJVee04OuLi8FAPQk+gEMvujJOoI1JH2gSW4iWGVZKb79gUUYP6LKcIvii24TzikzxuDrly/Ef39wkczJA4OVAmOM3E5NVXkJOnv7HcurBDl1udRjh1cEVWVZqeO+lC09U55nKoLy0uw3troiWVfqWuOSBTRqROW2meic+5+8Zh5WCowtPT6zimaS+wOuKi9Fd5+LUlB4+zp71WzHXuspVJa5jBSsQ516irlCv8oaKaSuNSKyzTjFZnsPEk5zwYSOnblF1Z6ZK+SryktdRwoqqNbjZG5K4aYU7EYKbqSUQldKKRSLVmCME4TiZUdzAdLRk0CiX6CqogRt3QmMralES0cvevsHUFddjp6+AbR29aG2KhkRc7Q7kf5+pLPPpd5+bNufdPCWlxKESArAtA29vx81lWUYVlGGI5292G5F4aTYfaQLm/ccdaz/ncOdjvtyUVUKb+63d0ynqCx3Mx8l/5XNhpm6H7oUYFzQrfyiYnZLy2GtjmbFkFRr+6H2Hn2NcICVgmb+9uYhzG8YgRFV8mvurnmnBVNGDUO9psXWL7vzBexs6cJpx4zByi0H8PHTp+NnNrH7qmzZ14ZzvvOsZ7kvXjQX/7l885Dtnb39+PT9axyPkxWiBMK00cOw+u2WrO3jRyTvX2ZYaIp1za22dVWWlaAnMYBj6mscz5caKWRGDp0wddSQcpPqkk7aYycm10de0FCHpzbtw4KGkR5XJM/U0cPSn6vLk6/viTZtmT+pDiu3HMC42irMHl8LAGgYOWxIOS/GOIRpqnBcQx1e3HYoHW6bYkFDHTbsGnwuM6xEeI1jshPindyYfVzTtNF4cdshzBzn/MxMIKMTTpw6EmveOeJZLndkWlNZhvaepEnUztlfZZVfvmEPznMJa9YBKwWNtHb24eqfvIQzZtc7hrfZ8Q8/+ism1VXhr7edraUdKYG4ckty0piKQqivrcRXLpmHmx54Nb0tJTi/ecVCVJWX4on1u13nH+QqhH84sSEZ7vi79dh1ZDC89dp3NeK8eePxj1b4awllh6WeNnMMrlg8GX39YkgI5u2XzsOSGWPQ0ZvAv/3fJlzZNCWdofORz5yGH63chruf2551zEULJuCyRQ1o6exFw8hqjBpWgdkTavDa7qNpwfr4jafjtkc2ZAmrVHw+EWHexBF462AHvnrZvKy6n77lzLQAvfzEBkwfOxwnTh2JpXPq00rCL3+99SwQJUdq9TWVWLFpLwBg5LByPHHT6bYK7bPnzMI588bjuIY6zJs4AidOG2WrPNx45pYzMWqYP6Xw1OfOgACw/UAHzjl2HN5/QgOmjMpWSvd/8hTszZircMXiyThmXA1OmDKoRFd89gw0jKpOf953tBtnzK7HmXPqs8rlwz+eMhVffnQjGhwmS+aaTa87rRE/f3GHbdlffuxk7MmZf3FS4yjcdPYsNI4Zjo7eBPa2dmPuhNqsMo/dcBpau5Kj9AWT6/CHz7wLhzt60TCqGjWVZZhYV42ffbQJE+v8zRlSgZWCRlI25E27nU0kuaSSq7lN5DHBx0+fjs+dOxu9iQFUlpVg/h0rACR7a5ctmoSLF0xMC2lC0iafspVfunAi+gcEiAh9/QPpMNPy0qTy6B8QqCgrQXV5adbchOe/8B4MCIHP/24dHl27Gwsa6vCumWPT+1d/+VzUVZenh+uZx15+4mR86Q8b8OArOwEAI4dV4IMnTQEAXHNqY1bZuupy3HbRsfjCBXPT2/sHBErIfnieKSyPa6jD3Am1tkoBSCoNsqknUzATERZPS9a5cHL+gsttZvf8SXW228tKS3C8JTRLSkhZIQDADJfRkx2ZsnOWNTpJjVLmThiqGEdUlWeNqImGtnNOhvCcM6E2/d3P9Tjx4SXT8OEl06TL5yq3TGqrylGbYyWor63Eu2fVp7/b3Yvce203Ej372PHSbcwHVgoaUY2IAQYVSdCUlhBqKsuAHItVStalhGkq2rKqpDSjDKHM2lFaUppWFgCyPudSUkIowWCsfq58Hl5ZhhKH2V1uE9+c9mVu95o4l0nuRLeKjKG+U/sYplAwGn1ERBcQ0RYi2kZEt9rsrySih6z9LxNRo8n2mMaPY7HDhyJxQzats/NaBDpbo0ZuvH9Y5M6BqHCJTGIGiYhf2BhRcXybxtivnYhKAfwQwIUA5gG4mojm5RT7OIAWIcRMAN8F8A1T7QmCjp6UgFeIt+/RO1LoTsjVF8WY8qi8dLmjN1YKDFA8801M/tpPBrBNCLFdCNEL4EEA780p814Av7Q+/x7A2RQVyeCDKIwUZNsQQZ0QGYYohVJWCsVMFDtQJjHpU2gAsDPjezOAU5zKCCESRNQKYAyAg7ob8+wbB/Dvj2/SXW0WqZCyg+29OFcidBPIFkCyx7jhuW6ARW6+nhSpFA0mSQlZFTs/MNhjLzNsZspt1vBK8/dEhZSZzekZBk3qeZYXqL8l9TtNhZGm7r/XCDJ1XNw6FSaVgt0vJFdiyZQBES0DsAwApk6d6qsxNZVlmDXefFxz95uH0NQ4Wsk+3j8gMHNcDWqr9DyOWeNq0NXXjxHV5djQ3IrxIypRV12B2eNrsONQB0qIcMNZM7OOuecji/HNFVvwzcsXammDG1+8+FiMGl6BixdMBAD85hOnYF+bd/TV58+fg+qKUteMpjr4zgePx1X3vITWrj5MGzMM15zaaPR8qlyycBI2723DZ5bO9C4cAB85dRoOtvfgU0uPCeX8j994Ota80+Jd0CcXHjcBnzrzGHz6zOT1ffCkKWhu6cKNZ89Kl3lw2RLsPpKdTfjceePx6aXHYNm71dKUhw2ZSsVKRKcC+KoQ4nzr+20AIIT4r4wyK6wyfyOiMgB7AdQLl0Y1NTWJVatWGWkzwzBMoUJEq4UQTV7lTI5rXgEwi4imE1EFgKsAPJZT5jEAH7U+XwHgGTeFwDAMw5jFmPnI8hHcAGAFgFIA9wohXiOirwFYJYR4DMDPAPyKiLYBOIyk4mAYhmFCwujkNSHEcgDLc7bdnvG5G8AHTLaBYRiGkSdebnGGYRjGKKwUGIZhmDSsFBiGYZg0rBQYhmGYNKwUGIZhmDTGJq+ZgogOAHjb5+FjYSCFRsThay4O+JqLg3yueZoQot6rUOyUQj4Q0SqZGX2FBF9zccDXXBwEcc1sPmIYhmHSsFJgGIZh0hSbUrgn7AaEAF9zccDXXBwYv+ai8ikwDMMw7hTbSIFhGIZxoWiUAhFdQERbiGgbEd0adnt0QERTiGglEb1ORK8R0c3W9tFE9BQRbbX+HWVtJyL6vnUP1hPRieFegX+IqJSIXiWix63v04noZeuaH7LStYOIKq3v26z9jWG22y9ENJKIfk9Em63nfWqhP2ci+pz1u95IRA8QUVWhPWciupeI9hPRxoxtys+ViD5qld9KRB+1O5csRaEUiKgUwA8BXAhgHoCriWheuK3SQgLALUKIYwEsAXC9dV23AnhaCDELwNPWdyB5/bOsv2UAfhx8k7VxM4DXM75/A8B3rWtuAfBxa/vHAbQIIWYC+K5VLo58D8CTQoi5ABYhee0F+5yJqAHATQCahBDHIZl+/yoU3nP+BYALcrYpPVciGg3gDiSXOz4ZwB0pReILIUTB/wE4FcCKjO+3Abgt7HYZuM7/BXAugC0AJlrbJgLYYn2+G8DVGeXT5eL0B2Cy9bKcBeBxJJd1PQigLPd5I7mex6nW5zKrHIV9DYrXOwLAW7ntLuTnjMH120dbz+1xAOcX4nMG0Ahgo9/nCuBqAHdnbM8qp/pXFCMFDP7AUjRb2woGa7h8AoCXAYwXQuwBAOvfcVaxQrkP/wPgCwAGrO9jABwRQiSs75nXlb5ma3+rVT5OzABwAMDPLZPZT4loOAr4OQshdgH4NoB3AOxB8rmtRmE/5xSqz1Xr8y4WpUA22wom7IqIagA8DOCzQoijbkVttsXqPhDRJQD2CyFWZ262KSok9sWFMgAnAvixEOIEAB0YNCnYEftrtswf7wUwHcAkAMORNJ/kUkjP2Quna9R67cWiFJoBTMn4PhnA7pDaohUiKkdSIdwvhHjE2ryPiCZa+ycC2G9tL4T7cBqAy4hoB4AHkTQh/Q+AkUSUWkkw87rS12ztr0Ny6dc40QygWQjxsvX990gqiUJ+zucAeEsIcUAI0QfgEQDvQmE/5xSqz1Xr8y4WpfAKgFlW5EIFkg6rx0JuU94QESG5zvXrQojvZOx6DEAqAuGjSPoaUtuvsaIYlgBoTQ1T44IQ4jYhxGQhRCOSz/EZIcSHAKwEcIVVLPeaU/fiCqt8rHqQQoi9AHYS0Rxr09kANqGAnzOSZqMlRDTM+p2nrrlgn3MGqs91BYDziGiUNcI6z9rmj7CdLAE6cy4C8AaANwF8Kez2aLqm05EcJq4HsNb6uwhJW+rTALZa/462yhOSUVhvAtiAZGRH6NeRx/UvBfC49XkGgL8D2AbgdwAqre1V1vdt1v4ZYbfb57UeD2CV9awfBTCq0J8zgH8DsBnARgC/AlBZaM8ZwANI+kz6kOzxf9zPcwXwMevatwG4Lp828YxmhmEYJk2xmI8YhmEYCVgpMAzDMGlYKTAMwzBpWCkwDMMwaVgpMAzDMGlYKTBFAxH1E9HajD/XbLlE9CkiukbDeXcQ0Vgfx51PRF+14s+X59sOhpGhzLsIwxQMXUKI42ULCyHuMtkYCd6N5GStMwC8GHJbmCKBlQJT9FgpMx4C8B5r0z8KIbYR0VcBtAshvk1ENwH4FJLpyjcJIa6yUhbfi+SEqk4Ay4QQ64loDJKTkuqRnEhFGef6MJIpoSuQTF74GSFEf057rkQyk+8MJPP/jAdwlIhOEUJcZuIeMEwKNh8xxUR1jvnoyox9R4UQJwO4E8lcSrncCuAEIcRCJJUDkJxx+6q17YsA7rO23wHgBZFMXvcYgKkAQETHArgSwGnWiKUfwIdyTySEeAjJ3EYbhRALkJzRewIrBCYIeKTAFBNu5qMHMv79rs3+9QDuJ6JHkUwzASTTjFwOAEKIZ4hoDBHVIWnu+Qdr+xNE1GKVPxvAYgCvJNP5oBqDyc5ymYVkOgMAGCaEaJO4PobJG1YKDJNEOHxOcTGSwv4yAF8hovlwT1lsVwcB+KUQ4ja3hhDRKgBjAZQR0SYAE4loLYAbhRDPu18Gw+QHm48YJsmVGf/+LXMHEZUAmCKEWInk4j4jAdQAeA6W+YeIlgI4KJLrWWRuvxDJ5HVAMrnZFUQ0zto3moim5TZECNEE4Akk/QnfRDKB4/GsEJgg4JECU0xUWz3uFE8KIVJhqZVE9DKSHaWrc44rBfBryzRESK4RfMRyRP+ciNYj6WhOpTv+NwAPENEaAM8imQYaQohNRPRlAH+yFE0fgOsBvG3T1hORdEh/BsB3bPYzjBE4SypT9FjRR01CiINht4VhwobNRwzDMEwaHikwDMMwaXikwDAMw6RhpcAwDMOkYaXAMAzDpGGlwDAMw6RhpcAwDMOkYaXAMAzDpPl/VdanaUUom44AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2261985b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ddpg(n_episodes=1000, max_t=1000):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        #restart env \n",
    "        env_itter = env.reset(train_mode=True)[brain_name] #note training = True here\n",
    "        #grab state of agents\n",
    "        state =env_itter.vector_observations\n",
    "        agent.reset()\n",
    "        score = np.zeros(len(env_itter.agents)) \n",
    "        \n",
    "        for t in range(max_t):\n",
    "            #select an action for each agent based off learned weights\n",
    "            #put a 1 instead of i_episodes if you do not want to decay the noise param\n",
    "            action = agent.act(state,i_episode,add_noise=True)\n",
    "            #send agents into env\n",
    "            env_itter = env.step(action)[brain_name]  \n",
    "            \n",
    "            #pull out env results\n",
    "            rewards = env_itter.rewards                      \n",
    "            dones = env_itter.local_done\n",
    "            next_states =env_itter.vector_observations\n",
    "            #train agents\n",
    "            agent.step(state, action, rewards, next_states, dones)\n",
    "            score += rewards      \n",
    "            state = next_states \n",
    "            #check if any agents finished\n",
    "            if np.any(dones):\n",
    "                break \n",
    "                \n",
    "        #note we now only append the max score over both agents to the final score tally\n",
    "        scores_deque.append(np.max(score))\n",
    "        scores.append(np.max(score))\n",
    "\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tMin Score: {:.2f}\\tMax Score: {:.2f}\\tEpisode score: {:.2f}'.format(i_episode, np.mean(scores_deque),np.min(scores_deque),np.max(scores_deque),np.mean(score)), end=\"\")\n",
    "        if i_episode % 25 == 0:\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))   \n",
    "        \n",
    "#         if np.mean(scores_deque) >= 0.5:\n",
    "#             print('\\nDone! Solved task in {} Episodes'.format(i_episode))\n",
    "#             torch.save(agent.actor_local.state_dict(), 'solved_actor.pth')\n",
    "#             torch.save(agent.critic_local.state_dict(), 'solved_critic.pth')\n",
    "#             break\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = ddpg()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save out the score file\n",
    "import pandas as pd\n",
    "pd.DataFrame(scores).to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nice, we solved the env in ~400 episodes!!\n",
    "\n",
    "The learning looks farily stable with this model arch and weighted noise approach.\n",
    "\n",
    "This version of DDPG makes 4 learning steps (4 samples from the replay buffer, and passes over the model). I thought this might yield an unstable agent; however, the agents are able to learn quickly and the performance does not degrade. In another test (over 2K episodes) the score slowly started to decrease after peaking at ~2.5 for a few hundred episodes. The number of agent steps should be experimented with to achieve optimal performance in the future. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas for future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much like the other implementation of DDPG on the reacher environment, I think my model architecture can be optimized. Normalizing the input for the critic network should improve the agents stability, enhancing long term performance. \n",
    "\n",
    "I really want to implement a PPO agent and compare/contrast the performance with my DDPG version. I will start with a basic PPO agent, and then replicate the DOTA playing one. This should enhance my understanding of a few actor/critic algorithms for multiple agent RL problems!\n",
    "\n",
    "These agents had very poor performance for the first 200 episodes. Experimenting with adding a prioritized replay buffer could help jump start the initial learning hurdles seen here. \n",
    "\n",
    "As I stated before, experimenting with the number of learning steps the network takes is a great next step. This will enhance my understanding of how much the agents learn off each sample of the replay buffer. \n",
    "\n",
    "I would also like to remove the noise scaler and allow the agents to experiment with their actions more. this might make it harder to learn initially, but they might benefit in the long run from exploring the state space for a longer period of time. \n",
    "\n",
    "Just as I stated in my last implementation of DDPG, it would be interesting to see if an RNN architecture could improve the results. Capturing temporal dependencies among past actions could improve the agents ability to discern optimal actions at the current time step. Combining the actor network with a Bidirectional LSTM encoder/decoder architecture will be my next experiment!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you Udacity for the course content and lesson structure that made this possible! I learned a ton from the RL work and am excited to continue exploration on my own"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
